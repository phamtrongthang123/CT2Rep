def nii_img_to_tensor(self, path, transform):
    img_data = np.load(path)["arr_0"]

    img_data= np.transpose(img_data, (1, 2, 0))
    img_data = img_data*1000
    hu_min, hu_max = -1000, 200
    img_data = np.clip(img_data, hu_min, hu_max)

    img_data = (((img_data+400 ) / 600)).astype(np.float32)
    slices=[]

    tensor = torch.tensor(img_data)

    # Get the dimensions of the input tensor
    target_shape = (480,480,240)
    
    # Extract dimensions
    h, w, d = tensor.shape

    # Calculate cropping/padding values for height, width, and depth
    dh, dw, dd = target_shape
    h_start = max((h - dh) // 2, 0)
    h_end = min(h_start + dh, h)
    w_start = max((w - dw) // 2, 0)
    w_end = min(w_start + dw, w)
    d_start = max((d - dd) // 2, 0)
    d_end = min(d_start + dd, d)

    # Crop or pad the tensor
    tensor = tensor[h_start:h_end, w_start:w_end, d_start:d_end]

    pad_h_before = (dh - tensor.size(0)) // 2
    pad_h_after = dh - tensor.size(0) - pad_h_before

    pad_w_before = (dw - tensor.size(1)) // 2
    pad_w_after = dw - tensor.size(1) - pad_w_before

    pad_d_before = (dd - tensor.size(2)) // 2
    pad_d_after = dd - tensor.size(2) - pad_d_before

    tensor = torch.nn.functional.pad(tensor, (pad_d_before, pad_d_after, pad_w_before, pad_w_after, pad_h_before, pad_h_after), value=-1)

    tensor = tensor.permute(2, 0, 1)
    
    tensor = tensor.unsqueeze(0).unsqueeze(0)
    return tensor[0]